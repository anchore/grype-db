package main

import (
	"database/sql"
	"encoding/csv"
	"encoding/json"
	"fmt"
	"github.com/anchore/grype-db/cmd/build-cve-set-lookup/termset"
	"github.com/anchore/grype-db/pkg/provider/unmarshal/nvd/cvss31"
	"github.com/bmatcuk/doublestar/v4"
	"github.com/facebookincubator/nvdtools/wfn"
	"github.com/fatih/camelcase"
	"github.com/mitchellh/go-homedir"
	"golang.org/x/exp/maps"
	"io"
	_ "modernc.org/sqlite"
	"net/http"
	"os"
	"path"
	"regexp"
	"slices"
	"strconv"
	"strings"
	"unicode"
)

func main() {
	nvdDbFile := "~/projects/grype-db/data/vunnel/nvd/results/results.db"
	//nvdCpeListFile := "~/Downloads/cvelistV5-main/official-cpe-dictionary_v2.3.xml"
	cveListDir := "~/Downloads/cvelistV5-main/cves"
	//cveJsonFileGlob := "2024/*/*.json" // */**/*.json
	cveJsonFileGlob := "*/**/*.json"
	csvFile := "~/projects/vunnel/src/classifier/product_version_all.csv"

	// expand easier to use paths
	cveListDir = panget(homedir.Expand(cveListDir))
	csvFile = panget(homedir.Expand(csvFile))

	if len(os.Args) > 1 {
		action := os.Args[1]
		switch action {
		case "show-descriptions":
			showDesriptions(csvFile, cveListDir, os.Args[2])
			return
		}
	}

	lookups := exampleTextLookups(cveListDir)

	//lookups := []string{
	//	//CVE-2024-25126,true,ruby,https://github.com/rack/rack,https://github.com/advisories/GHSA-22f2-v57c-j9cx
	//	"Rack is a modular Ruby web server interface. Carefully crafted content type headers can cause Rackâ€™s media type parser to take much longer than expected, leading to a possible denial of service vulnerability (ReDos 2nd degree polynomial). This vulnerability is patched in 3.0.9.1 and 2.2.8.1.",
	//	//CVE-2024-26150,true,typescript,https://github.com/backstage/backstage,https://github.com/advisories/GHSA-2fc9-xpp8-2g9h
	//	"`@backstage/backend-common` is a common functionality library for backends for Backstage, an open platform for building developer portals. In `@backstage/backend-common` prior to versions 0.21.1, 0.20.2, and 0.19.10, paths checks with the `resolveSafeChildPath` utility were not exhaustive enough, leading to risk of path traversal vulnerabilities if symlinks can be injected by attackers. This issue is patched in `@backstage/backend-common` versions 0.21.1, 0.20.2, and 0.19.10.",
	//	//CVE-2024-26129,true,php,https://github.com/PrestaShop/PrestaShop,https://github.com/advisories/GHSA-3366-9287-7qpr
	//	"PrestaShop is an open-source e-commerce platform. Starting in version 8.1.0 and prior to version 8.1.4, PrestaShop is vulnerable to path disclosure in a JavaScript variable. A patch is available in version 8.1.4.",
	//	//CVE-2024-22369,true,java,https://github.com/apache/camel,https://github.com/advisories/GHSA-36xr-4x2f-cfj9
	//	"Deserialization of Untrusted Data vulnerability in Apache Camel SQL ComponentThis issue affects Apache Camel: from 3.0.0 before 3.21.4, from 3.22.0 before 3.22.1, from 4.0.0 before 4.0.4, from 4.1.0 before 4.4.0.\n\nUsers are recommended to upgrade to version 4.4.0, which fixes the issue. If users are on the 4.0.x LTS releases stream, then they are suggested to upgrade to 4.0.4. If users are on 3.x, they are suggested to move to 3.21.4 or 3.22.1\n\n",
	//	//CVE-2024-26134,true,c,https://github.com/agronholm/cbor2,https://github.com/advisories/GHSA-375g-39jq-vq7m
	//	"cbor2 provides encoding and decoding for the Concise Binary Object Representation (CBOR) (RFC 8949) serialization format. Starting in version 5.5.1 and prior to version 5.6.2, an attacker can crash a service using cbor2 to parse a CBOR binary by sending a long enough object. Version 5.6.2 contains a patch for this issue.",
	//	//CVE-2024-23493,true,typescript,https://github.com/mattermost/mattermost,https://github.com/advisories/GHSA-7v3v-984v-h74r
	//	"Mattermost fails to properly authorize the requests fetching team associated AD/LDAP groups, allowing a user to fetch details of AD/LDAP groups of a team that they are not a member of",
	//}

	nvdDbFile = panget(homedir.Expand(nvdDbFile))
	nvdDb := panget(sql.Open("sqlite", nvdDbFile))
	defer func() {
		panif(nvdDb.Close())
	}()

	//allDbFiles := "~/projects/grype-db/data/vunnel/*/results/results.db"

	timer := newTimer()

	cpeToVendorProduct := readCpeToVendorProduct(nvdDb)
	timer.snap()

	var knownRecords []rec
	paths := panget(doublestar.FilepathGlob(path.Join(cveListDir, cveJsonFileGlob)))
	for _, p := range paths {
		for _, item := range readCveFile(cpeToVendorProduct, p) {
			knownRecords = append(knownRecords, item)
		}
	}

	log("known record count: %v", len(knownRecords))

	termToVendorProduct, byVendorProduct, removeWords := buildLookups(knownRecords)
	csvLines := [][]string{{"product", "cves", "text"}}
	for cpeVendorProduct, product := range byVendorProduct {
		txt := strings.Join(product.terms.List(), " ")
		cves := strings.Join(product.cves, " ")
		csvLines = append(csvLines, []string{cpeVendorProduct, cves, txt})
	}
	writeCSVFile(csvFile, csvLines)

	// lookup:
	for i, searchText := range lookups {
		if i == 2 {
			fmt.Print()
		}

		searchTerms := getTextTerms(searchText)
		searchTerms.Remove(removeWords.List()...)

		found := lookupProduct(termToVendorProduct, byVendorProduct, searchTerms)

		fmt.Printf("SEARCH '%s':", searchText)
		fmt.Println()
		for _, m := range found {
			fmt.Printf("  - %s (%.2f%%)", m.cpeVendorProduct, getMatchPercent(m, searchTerms)*100)
			fmt.Println()
		}

		fmt.Println()
	}
}

type cveRecord struct {
	CveMetadata struct {
		ID string `json:"cveId"`
	} `json:"cveMetadata"`
	Containers struct {
		Cna struct {
			Affected []struct {
				Vendor      string `json:"vendor"`
				Product     string `json:"product"`
				PackageName string `json:"packageName"`
				Versions    []struct {
					Version     string `json:"version"`
					VersionType string `json:"versionType"`
					LessThan    string `json:"lessThan"`
				} `json:"versions"`
				Cpes []string `json:"cpes"`
			} `json:"affected"`
			References []struct {
				Url string `json:"url"`
			} `json:"references"`
			Descriptions []struct {
				Lang  string `json:"lang"`
				Value string `json:"value"`
			} `json:"descriptions"`
			Metrics []struct {
				cvss31.Cvss31 `json:"cvssV3_1"`
			} `json:"metrics"`
		} `json:"cna"`
	} `json:"containers"`
}

func cveFileName(cveListDir, cve string) string {
	parts := strings.Split(cve, "-")
	year := parts[1]
	num := parts[2]
	subdir := fmt.Sprintf("%sxxx", num[0:len(num)-3])
	return path.Join(cveListDir, year, subdir, fmt.Sprintf("CVE-%s-%s.json", year, num))
}

func exampleTextLookups(cveListDir string) []string {
	var out []string

	rdr := csv.NewReader(panget(os.Open(panget(homedir.Expand("~/Downloads/candidates.csv")))))
	_, _ = rdr.Read() // skip headers
	for row, err := rdr.Read(); err == nil; row, err = rdr.Read() {
		cve := row[0]

		cveFile := logget(os.ReadFile(cveFileName(cveListDir, cve)))
		if cveFile == nil {
			continue
		}

		var cveRec cveRecord
		logif(json.Unmarshal(cveFile, &cveRec))

		if cveRec.CveMetadata.ID == "" {
			log("no cveId in:", cveFile)
			continue
		}

		var text []string
		for _, reference := range cveRec.Containers.Cna.References {
			url := reference.Url
			if url != "" {
				text = append(text, url)
			}
		}

		for _, description := range cveRec.Containers.Cna.Descriptions {
			if description.Lang == "en" {
				text = append(text, description.Value)
			}
		}

		if len(text) == 0 {
			log("no usable text in: ", cveFile)
			continue
		}

		out = append(out, strings.Join(text, " "))
	}

	return out
}

func showDesriptions(csvFile, cveListDir string, vendorProduct string) {
	rdr := csv.NewReader(panget(os.Open(csvFile)))
	// skip header row
	_, _ = rdr.Read() // skip headers
	for row, err := rdr.Read(); err == nil; row, err = rdr.Read() {
		if vendorProduct == row[0] {
			for _, cve := range strings.Split(row[1], " ") {
				matched := panget(doublestar.FilepathGlob(path.Join(cveListDir, "**", strings.ToUpper(cve)+".json")))
				if len(matched) != 1 {
					panic(fmt.Sprintf("incorrect CVE file matches: %v", matched))
				}
				cveFile := matched[0]

				var cveRec cveRecord
				logif(json.Unmarshal(logget(os.ReadFile(cveFile)), &cveRec))

				if cveRec.CveMetadata.ID == "" {
					log("no cveId in:", cveFile)
					continue
				}

				var text []string
				for _, reference := range cveRec.Containers.Cna.References {
					url := reference.Url
					if url != "" {
						text = append(text, url)
					}
				}

				for _, description := range cveRec.Containers.Cna.Descriptions {
					if description.Lang == "en" {
						text = append(text, description.Value)
					}
				}

				if len(text) == 0 {
					log("no usable text in: ", cveFile)
					continue
				}

				fmt.Printf("%s:", cveFile)
				fmt.Println()
				for _, part := range text {
					fmt.Printf("    %s", part)
					fmt.Println()
				}
			}
			return
		}
	}
}

func lookupProduct(termToVendorProduct map[string]termset.Set, byVendorProduct map[string]*product, searchTerms termset.Set) []*product {
	// get all products that match _any_ term
	matchesAny := termset.Set{}
	for term := range searchTerms {
		vendorProducts := termToVendorProduct[term]
		if vendorProducts != nil {
			matchesAny.AddAll(vendorProducts)
		}
	}

	var out []*product

	for vendorProduct := range matchesAny {
		p := byVendorProduct[vendorProduct]
		if p != nil {
			out = append(out, p)
		}
	}

	slices.SortFunc(out, func(a, b *product) int {
		if a == nil && b == nil {
			return 0
		}
		if a == nil {
			return -1
		}
		if b == nil {
			return 1
		}

		aPct := getMatchPercent(a, searchTerms)
		bPct := getMatchPercent(b, searchTerms)

		if aPct == bPct {
			return strings.Compare(a.cpeVendorProduct, b.cpeVendorProduct)
		}
		if aPct < bPct {
			return 1
		}
		return -1
	})

	// if there are multiple matches and there is one with more matching terms, use it
	//if len(out) > 1 && out[0].terms.Size() > out[1].terms.Size() {
	//	return []*product{out[0]}
	//}

	if len(out) > 5 {
		return out[0:5]
	}

	return out
}

func getMatchPercent(p *product, searchTerms termset.Set) float64 {
	matchCount := 0.
	for term := range p.terms {
		// don't count single-digit number matches... ehhh
		if len(term) == 1 && unicode.IsDigit(rune(term[0])) {
			continue
		}
		if searchTerms.Has(term) {
			matchCount++
		}
	}
	return matchCount / float64(len(p.terms))
}

func buildLookups(knownRecords []rec) (termToVendorProduct map[string]termset.Set, byVendorProduct map[string]*product, removeWords termset.Set) {
	termToVendorProduct = map[string]termset.Set{}
	byVendorProduct = map[string]*product{}

	for _, knownRecord := range knownRecords {
		// only construct lookup data out of known mappings
		if len(knownRecord.cpeVendorProducts) != 1 {
			continue
		}

		terms := getTerms(knownRecord)

		switch knownRecord.cve {
		case "cve-2024-1722":
			fmt.Print()
		}

		for cpeVendorProduct := range knownRecord.cpeVendorProducts {
			existing := byVendorProduct[cpeVendorProduct]
			if existing == nil {
				prod := &product{
					cves:             []string{knownRecord.cve},
					cpeVendorProduct: cpeVendorProduct,
					terms:            terms,
				}
				byVendorProduct[cpeVendorProduct] = prod
				for term := range prod.terms {
					s := termToVendorProduct[term]
					if s == nil {
						s = termset.Set{}
						termToVendorProduct[term] = s
					}
					s.Add(cpeVendorProduct)
				}

				continue
			}

			// add the cve
			existing.cves = append(existing.cves, knownRecord.cve)

			// if we find existing records, remove terms that are not in both sets
			for existingTerm := range existing.terms {
				if !terms.Has(existingTerm) {
					existing.terms.Remove(existingTerm)
					s := termToVendorProduct[existingTerm]
					if s != nil {
						s.Remove(existing.cpeVendorProduct)
					}
				}
			}
		}
	}

	return removeHighFrequencyTerms(termToVendorProduct, byVendorProduct, 1000)
}

var vendorProductSplit = regexp.MustCompile(`[^\-\pL]+`)

var skipWords = termset.New(
	"the",
	"for",
	"sys",
	"non",
	"vulnerability",
)

var keepWords = termset.New(
	"php",
	"android",
	"java",
	"ibm",
	"github",
	"microsoft",
)

var shortWordMatch = regexp.MustCompile(`^\pL\pL?$`)

func removeHighFrequencyTerms(termToVendorProduct map[string]termset.Set, byVendorProduct map[string]*product, topNumWords int) (map[string]termset.Set, map[string]*product, termset.Set) {
	termCounts := termset.Set{}
	for _, p := range byVendorProduct {
		termCounts.AddAll(p.terms)
	}

	// get terms sorted by frequency
	terms := maps.Keys(termToVendorProduct)
	slices.SortFunc(terms, func(a, b string) int {
		numA := termCounts[a]
		numB := termCounts[b]
		if numA == numB {
			return strings.Compare(a, b)
		}
		if numA > numB {
			return -1
		}
		return 1
	})

	// set up keep words, from known list and parts of vendorProducts
	//keep := termset.New(keepWords.List()...)
	//for vp := range byVendorProduct {
	//
	//	for _, part := range vendorProductSplit.Split(vp, -1) {
	//		// 1 or 2-letter words are not especially useful
	//		if part == "" || skipWords.Has(part) || shortWordMatch.MatchString(part) {
	//			continue
	//		}
	//		keep.Add(part)
	//	}
	//}

	removeWords := termset.Set{}
	for _, term := range terms {
		if keepWords.Has(term) || isNumber(term) {
			continue
		}

		vendorProducts := termToVendorProduct[term]
		for vendorProduct := range vendorProducts {
			// if the vendorProduct text has the term, keep it regardless of the frequency seen
			keep := getTextTerms(vendorProduct)
			if keep.Has(term) {
				continue
			}

			p := byVendorProduct[vendorProduct]
			p.terms.Remove(term)
			if len(p.terms) == 0 {
				delete(byVendorProduct, vendorProduct)
			}
			vendorProducts.Remove(vendorProduct)
		}

		// if the term was not something in a vendorProduct string, delete the index entry
		if len(vendorProducts) == 0 {
			delete(termToVendorProduct, term)
		}

		removeWords.Add(term)
		topNumWords--
		if topNumWords <= 0 {
			break
		}
	}

	return termToVendorProduct, byVendorProduct, removeWords
}

func countTermInProducts(term string, byVendorProduct map[string]*product, vendorProducts termset.Set) float64 {
	total := 0.
	for vendorProduct := range vendorProducts {
		p := byVendorProduct[vendorProduct]
		if p != nil {
			total += p.terms[term]
		}
	}
	return total
}

func isNumber(term string) bool {
	_, err := strconv.ParseFloat(term, 64)
	return err == nil
}

func isHashLike(term string) bool {
	if len(term) < 6 {
		return false
	}

	numberFollowsLetter := 0
	letterFollowsNumber := 0
	last := rune(term[0])
	for _, chr := range term[1:] {
		if unicode.IsDigit(last) && unicode.IsLetter(chr) {
			letterFollowsNumber++
		}
		if unicode.IsLetter(last) && unicode.IsDigit(chr) {
			numberFollowsLetter++
		}
		last = chr
	}

	return numberFollowsLetter > 1 && letterFollowsNumber > 1
}

func readCveFile(cveToVendorProduct map[string][]string, cveFile string) (records []rec) {
	var cveRec cveRecord
	logif(json.Unmarshal(logget(os.ReadFile(cveFile)), &cveRec))

	if cveRec.CveMetadata.ID == "" {
		log("no cveId in:", cveFile)
		return nil
	}

	var text []string
	for _, reference := range cveRec.Containers.Cna.References {
		url := reference.Url
		if url != "" {
			text = append(text, url)
		}
	}

	for _, description := range cveRec.Containers.Cna.Descriptions {
		if description.Lang == "en" {
			text = append(text, description.Value)
		}
	}

	if len(text) == 0 {
		log("no usable text in: ", cveFile)
		return nil
	}

	cveId := normalizeCve(cveRec.CveMetadata.ID)

	for _, a := range cveRec.Containers.Cna.Affected {
		item := rec{
			cve:               cveId,
			text:              append([]string{a.Vendor, a.Product, a.PackageName}, text...),
			cpeVendorProducts: termset.Set{},
		}

		// if there are CPEs explicitly defined, use those
		for _, c := range a.Cpes {
			cpe, _ := wfn.Parse(fmt.Sprintf("%v", c))
			if cpe == nil {
				continue
			}
			cpeVendorProduct := toVendorProduct(cpe)
			item.cpeVendorProducts.Add(cpeVendorProduct)
		}

		// otherwise, look up CPEs from existing records if there is a definitive single CPE
		if len(a.Cpes) == 0 && len(cveToVendorProduct[cveId]) == 1 {
			for _, vendorProduct := range cveToVendorProduct[cveId] {
				item.cpeVendorProducts.Add(vendorProduct)
			}
		}

		// skip records with not exactly 1 distinct vendorProduct identified
		if len(item.cpeVendorProducts) != 1 {
			continue
		}

		records = append(records, item)
	}

	return records
}

func toVendorProduct(w *wfn.Attributes) string {
	//vendorProduct := fmt.Sprintf("%s:%s:%s:%s", w.Part, w.Vendor, w.Product, w.TargetSW)
	vendorProduct := fmt.Sprintf("%s:%s:%s", w.Vendor, w.Product, w.TargetSW)
	vendorProduct = strings.ReplaceAll(vendorProduct, "\\", "")
	return vendorProduct
}

func getTerms(r rec) termset.Set {
	out := termset.Set{}
	for _, txt := range r.text {
		out.AddAll(getTextTerms(txt))
	}
	return out
}

var urlPat = regexp.MustCompile(`https?://[^\s]+`)
var urlSplitter = regexp.MustCompile(`[./]`)

var keepHosts = termset.New(
	"github.com",
)

// processes the text, returning a searchable set of individual terms
func getTextTerms(t string) termset.Set {
	// split urls based on segments, e.g. github.com/org/repo will have distinct tokens
	t = urlPat.ReplaceAllStringFunc(t, func(s string) string {
		parts := urlSplitter.Split(t, -1)
		if !keepHosts.Has(parts[0]) {
			return ""
		}
		return strings.Join(parts, " ")
	})

	out := termset.Set{}

	for _, word := range whitespace.Split(t, -1) {
		if word == "" || isHashLike(word) {
			continue
		}

		out.Add(extractVariations(word)...)
		for _, part := range camelcase.Split(word) {
			out.Add(extractVariations(part)...)
		}
	}

	return out
}

func extractVariations(word string) []string {
	var out []string
	word = strings.ToLower(word)
	word = disallowedChars.ReplaceAllString(word, "")
	if word == "" {
		return nil
	}
	// each word we get like some.thing some-thing some_thing split into separate words "some thing" and combine to "something"
	out = append(out, word)
	out = append(out, disallowedChars.Split(word, -1)...)
	return out
}

type product struct {
	cpeVendorProduct string
	cves             []string
	terms            termset.Set
}

func writeCSVFile(file string, records [][]string) {
	f := panget(os.Create(file))
	defer func() {
		logif(f.Close())
	}()
	writeCSV(f, records)
}

func writeCSV(writer io.Writer, records [][]string) {
	for _, r := range records {
		writeRow(writer, r...)
	}
}

func writeRow(writer io.Writer, values ...string) {
	for i, v := range values {
		if i > 0 {
			_ = logget(fmt.Fprint(writer, `,`))
		}
		_ = logget(fmt.Fprintf(writer, `"%s"`, v))
	}
	_ = logget(fmt.Fprintln(writer))
}

var stopwords = fetchStopwords()

func fetchStopwords() map[string]struct{} {
	//url := "https://raw.githubusercontent.com/stopwords-iso/stopwords-en/master/stopwords-en.txt"
	url := "https://gist.githubusercontent.com/rg089/35e00abf8941d72d419224cfd5b5925d/raw/12d899b70156fd0041fa9778d657330b024b959c/stopwords.txt"

	rsp := panget(http.Get(url))
	defer func() {
		logif(rsp.Body.Close())
	}()

	list := string(panget(io.ReadAll(rsp.Body)))

	words := map[string]struct{}{}
	for _, word := range strings.Split(list, "\n") {
		word = strings.TrimSpace(word)
		word = strings.ToLower(word)
		words[word] = struct{}{}
	}

	return words
}

func removeStopwords(s string) string {
	out := ""
	for _, word := range strings.Split(s, " ") {
		word = strings.TrimSpace(word)
		word = strings.ToLower(word)
		if _, ok := stopwords[word]; ok {
			continue
		}
		// more stopwords
		switch word {
		case "", "n/a", "vulnerability", "http", "https", "version":
			continue
		}
		if len(out) > 0 {
			out += " "
		}
		out += word
	}

	return out
}

//func train(csvData io.ReadSeeker) {
//	rawData, err := base.ParseCSVToInstancesFromReader(csvData, true)
//	if err != nil {
//		panic(err)
//	}
//}

//var alpha = regexp.MustCompile("[a-z ]+")

func isKnownVersionType(versionType string) bool {
	versionType = strings.ToLower(versionType)
	switch versionType {
	case "general", "release", "patch", "python", "rpm", "affected", "general availability", "semver", "maven", "original_commit_for_fix":
		return true
	default:
		return false
	}
	//return alpha.MatchString(versionType)
}

type rec struct {
	cve  string
	text []string
	//versions          []string
	cpeVendorProducts termset.Set
}
