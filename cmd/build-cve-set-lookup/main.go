package main

import (
	"database/sql"
	"encoding/csv"
	"encoding/json"
	"fmt"
	"github.com/anchore/grype-db/cmd/build-cve-set-lookup/termset"
	"github.com/anchore/grype-db/pkg/provider/unmarshal/nvd/cvss31"
	"github.com/bmatcuk/doublestar/v4"
	"github.com/dustin/go-humanize"
	"github.com/facebookincubator/nvdtools/wfn"
	"github.com/mitchellh/go-homedir"
	"golang.org/x/exp/maps"
	"io"
	_ "modernc.org/sqlite"
	"net/http"
	"os"
	"path"
	"regexp"
	"runtime"
	"slices"
	"strconv"
	"strings"
	"unicode"
)

func main() {
	nvdDbFile := "~/projects/grype-db/data/vunnel/nvd/results/results.db"
	//nvdCpeListFile := "~/Downloads/cvelistV5-main/official-cpe-dictionary_v2.3.xml"
	cveListDir := "~/Downloads/cvelistV5-main/cves-2024-03-05"
	cveJsonFileGlob := "*/**/*.json"
	//cveJsonFileGlob = "2024/*/*.json"
	//cveJsonFileGlob = "*/**/CVE-{1999-0947,2005-1086,2005-1087}.json"
	csvFile := "~/projects/vunnel/src/classifier/product_version_all.csv"
	//allDbFiles := "~/projects/grype-db/data/vunnel/*/results/results.db"

	// expand easier to use paths
	cveListDir = panget(homedir.Expand(cveListDir))
	csvFile = panget(homedir.Expand(csvFile))

	defer func() {
		memStats := runtime.MemStats{}
		runtime.ReadMemStats(&memStats)
		log("used memory:", humanize.Bytes(memStats.Alloc))
	}()

	if len(os.Args) > 1 {
		action := os.Args[1]
		switch action {
		case "show-descriptions":
			showDescriptions(csvFile, cveListDir, os.Args[2])
			return
		}
	}

	lookups := []string{
		//"CVE-2023-46951",
		//"CVE-2023-49250",
		//"CVE-2023-51931",
		//"CVE-2024-1297",
		//"CVE-2024-1722",
		//"CVE-2024-1892",
		//"CVE-2024-21502",
		//"CVE-2024-22369",
		//"CVE-2024-24758",
		//"CVE-2024-25126",
		//"CVE-2024-25625",
		//"CVE-2024-26308",
		//"CVE-2024-27133",
	}

	lookups = cvesFromCSV("~/Downloads/candidates.csv")

	nvdDbFile = panget(homedir.Expand(nvdDbFile))
	nvdDb := panget(sql.Open("sqlite", nvdDbFile))
	defer func() { logif(nvdDb.Close()) }()

	timer := newTimer()

	var knownRecords []rec
	paths := panget(doublestar.FilepathGlob(path.Join(cveListDir, cveJsonFileGlob)))
	//wg := sync.WaitGroup{}
	//records := make(chan rec)
	//go func() {
	//	for {
	//		r, ok := <-records
	//		if !ok {
	//			break
	//		}
	//		knownRecords = append(knownRecords, r)
	//	}
	//}()
	for _, p := range paths {
		//wg.Add(1)
		//go func() {
		//	defer wg.Done()
		for _, item := range readCveFile(p) {
			//records <- item
			knownRecords = append(knownRecords, item)
		}
		//}()
	}
	//wg.Wait()
	//close(records)
	timer.snap("readCveFiles")

	cpeToVendorProduct := readCpeToVendorProduct(nvdDb)
	timer.snap("readCpeToVendorProduct")
	log("known record count: %v", len(knownRecords))

	knownRecords = filterKnownRecordsToSingleCpe(cpeToVendorProduct, knownRecords)
	timer.snap("filterKnownRecordsToSingleCpe")
	log("single-cpe record count: %v", len(knownRecords))

	//termToVendorProduct, byVendorProduct, removeWords := buildLookups(knownRecords)
	termToVendorProduct, byVendorProduct, _ := buildLookups(knownRecords)
	timer.snap("buildLookups")

	csvLines := [][]string{{"product", "cves", "text"}}
	for cpeVendorProduct, product := range byVendorProduct {
		txt := strings.Join(product.terms.List(), " ")
		cves := strings.Join(product.cves, " ")
		csvLines = append(csvLines, []string{cpeVendorProduct, cves, txt})
	}
	writeCSVFile(csvFile, csvLines)

	// lookup:
	for _, cve := range lookups {
		searchText := searchTextFromCVE(cveListDir, cve)
		searchTerms := getTextTerms(searchText)
		//searchTerms.Remove(removeWords.List()...)

		found := lookupProduct(termToVendorProduct, byVendorProduct, searchTerms)

		fmt.Printf("SEARCH '%s':", searchText)
		fmt.Println()
		for _, m := range found {
			fmt.Printf("  - %s (%.2f%%)", m.cpeVendorProduct, getMatchPercent(m, searchTerms)*100)
			fmt.Println()
		}

		fmt.Println()
	}
}

func filterKnownRecordsToSingleCpe(cveToVendorProduct map[string][]string, records []rec) []rec {
	var out []rec
	for _, r := range records {
		r, ok := filterKnownRecordToSingleCpe(cveToVendorProduct, r)
		if ok {
			out = append(out, r)
		}
	}
	return out
}

func filterKnownRecordToSingleCpe(cveToVendorProduct map[string][]string, r rec) (rec, bool) {
	// otherwise, look up CPEs from existing records if there is a definitive single CPE
	if len(r.cpeVendorProducts) == 0 && len(cveToVendorProduct[r.cve]) == 1 {
		for _, vendorProduct := range cveToVendorProduct[r.cve] {
			r.cpeVendorProducts.Add(vendorProduct)
		}
	}

	// skip records with not exactly 1 distinct vendorProduct identified
	if len(r.cpeVendorProducts) != 1 {
		return r, false
	}

	return r, true
}

type cveRecord struct {
	CveMetadata struct {
		ID    string `json:"cveId"`
		State string `json:"state"`
	} `json:"cveMetadata"`
	Containers struct {
		Cna struct {
			Affected []struct {
				Vendor      string `json:"vendor"`
				Product     string `json:"product"`
				PackageName string `json:"packageName"`
				Versions    []struct {
					Version     string `json:"version"`
					VersionType string `json:"versionType"`
					LessThan    string `json:"lessThan"`
				} `json:"versions"`
				Cpes []string `json:"cpes"`
			} `json:"affected"`
			References []struct {
				Url string `json:"url"`
			} `json:"references"`
			Descriptions []struct {
				Lang  string `json:"lang"`
				Value string `json:"value"`
			} `json:"descriptions"`
			Metrics []struct {
				cvss31.Cvss31 `json:"cvssV3_1"`
			} `json:"metrics"`
		} `json:"cna"`
	} `json:"containers"`
}

func cveFileName(cveListDir, cve string) string {
	parts := strings.Split(cve, "-")
	year := parts[1]
	num := parts[2]
	subdir := fmt.Sprintf("%sxxx", num[0:len(num)-3])
	return path.Join(cveListDir, year, subdir, fmt.Sprintf("CVE-%s-%s.json", year, num))
}

func cvesFromCSV(csvFile string) []string {
	var cves []string
	rdr := csv.NewReader(panget(os.Open(panget(homedir.Expand(csvFile)))))
	_, _ = rdr.Read() // skip headers
	for row, err := rdr.Read(); err == nil; row, err = rdr.Read() {
		cves = append(cves, row[0])
	}
	return cves
}

func searchTextFromCVE(cveListDir string, cve string) string {
	cveFile := logget(os.ReadFile(cveFileName(cveListDir, cve)))
	if cveFile == nil {
		log("file not found for:", cveListDir, cve)
		return ""
	}

	var cveRec cveRecord
	logif(json.Unmarshal(cveFile, &cveRec))

	var text []string
	for _, reference := range cveRec.Containers.Cna.References {
		url := reference.Url
		if url != "" {
			text = append(text, url)
		}
	}

	for _, description := range cveRec.Containers.Cna.Descriptions {
		if description.Lang == "en" {
			text = append(text, description.Value)
		}
	}

	return cveRec.CveMetadata.ID + " " + strings.Join(text, " ")
}

func showDescriptions(csvFile, cveListDir string, vendorProduct string) {
	rdr := csv.NewReader(panget(os.Open(csvFile)))
	// skip header row
	_, _ = rdr.Read() // skip headers
	for row, err := rdr.Read(); err == nil; row, err = rdr.Read() {
		if strings.Contains(row[0], "washington") {
			fmt.Print()
		}
		if vendorProduct == row[0] {
			for _, cve := range strings.Split(row[1], " ") {
				matched := panget(doublestar.FilepathGlob(path.Join(cveListDir, "**", strings.ToUpper(cve)+".json")))
				if len(matched) != 1 {
					panic(fmt.Sprintf("incorrect CVE file matches: %v", matched))
				}
				cveFile := matched[0]

				var cveRec cveRecord
				logif(json.Unmarshal(logget(os.ReadFile(cveFile)), &cveRec))

				if cveRec.CveMetadata.ID == "" {
					log("no cveId in:", cveFile)
					continue
				}

				var text []string
				for _, reference := range cveRec.Containers.Cna.References {
					url := reference.Url
					if url != "" {
						text = append(text, url)
					}
				}

				for _, description := range cveRec.Containers.Cna.Descriptions {
					if description.Lang == "en" {
						text = append(text, description.Value)
					}
				}

				fmt.Printf("%s:", cveFile)
				fmt.Println()
				for _, part := range text {
					fmt.Printf("    %s", part)
					fmt.Println()
				}
			}
			return
		}
	}
}

func lookupProduct(termToVendorProduct map[string]termset.Set, byVendorProduct map[string]*product, searchTerms termset.Set) []*product {
	// get all products that match _any_ term
	matchesAny := termset.Set{}
	for term := range searchTerms {
		vendorProducts := termToVendorProduct[term]
		if vendorProducts != nil {
			matchesAny.AddAll(vendorProducts)
		}
	}

	var out []*product

	for vendorProduct := range matchesAny {
		p := byVendorProduct[vendorProduct]
		if p != nil {
			out = append(out, p)
		}
	}

	slices.SortFunc(out, func(a, b *product) int {
		if a == nil && b == nil {
			return 0
		}
		if a == nil {
			return -1
		}
		if b == nil {
			return 1
		}

		aPct := getMatchPercent(a, searchTerms)
		bPct := getMatchPercent(b, searchTerms)

		if aPct == bPct {
			return strings.Compare(a.cpeVendorProduct, b.cpeVendorProduct)
		}
		if aPct < bPct {
			return 1
		}
		return -1
	})

	// if there are multiple matches and there is one with more matching terms, use it
	//if len(out) > 1 && out[0].terms.Size() > out[1].terms.Size() {
	//	return []*product{out[0]}
	//}

	// favor matches that have at least something matching in the vendorProduct string
	var directMatches []*product
	for _, p := range out {
		for term := range getTextTerms(p.cpeVendorProduct) {
			if searchTerms.Has(term) {
				directMatches = append(directMatches, p)
				break
			}
		}
	}

	if len(directMatches) > 0 {
		out = append(directMatches, out...)
	}

	if len(out) > 5 {
		return out[0:5]
	}

	return out
}

func getMatchPercent(p *product, searchTerms termset.Set) float64 {
	matchCount := 0.
	for term := range p.terms {
		// don't count single-digit number matches... ehhh
		if len(term) == 1 && unicode.IsDigit(rune(term[0])) {
			continue
		}
		if searchTerms.Has(term) {
			matchCount++
		}
	}
	return matchCount / float64(len(p.terms))
}

func buildLookups(knownRecords []rec) (termToVendorProduct map[string]termset.Set, byVendorProduct map[string]*product, removeWords termset.Set) {
	termToVendorProduct = map[string]termset.Set{}
	byVendorProduct = map[string]*product{}

	for _, knownRecord := range knownRecords {
		// only construct lookup data out of known mappings
		if len(knownRecord.cpeVendorProducts) != 1 {
			continue
		}

		terms := getTerms(knownRecord)

		switch knownRecord.cve {
		case "cve-2024-1722":
			fmt.Print()
		}

		for cpeVendorProduct := range knownRecord.cpeVendorProducts {
			existing := byVendorProduct[cpeVendorProduct]
			if existing == nil {
				prod := &product{
					cves:             []string{knownRecord.cve},
					cpeVendorProduct: cpeVendorProduct,
					terms:            terms,
				}
				byVendorProduct[cpeVendorProduct] = prod
				for term := range prod.terms {
					s := termToVendorProduct[term]
					if s == nil {
						s = termset.Set{}
						termToVendorProduct[term] = s
					}
					s.Add(cpeVendorProduct)
				}

				continue
			}

			// add the cve
			existing.cves = append(existing.cves, knownRecord.cve)

			// if we find existing records, remove terms that are not in both sets
			for existingTerm := range existing.terms {
				if !terms.Has(existingTerm) {
					existing.terms.Remove(existingTerm)
					s := termToVendorProduct[existingTerm]
					if s != nil {
						s.Remove(existing.cpeVendorProduct)
					}
				}
			}
		}
	}

	return removeHighFrequencyTerms(termToVendorProduct, byVendorProduct, 1000)
}

var vendorProductSplit = regexp.MustCompile(`[^\-\pL]+`)

var skipWords = termset.New(
	"the",
	"for",
	"sys",
	"non",
	"vulnerability",
)

var keepWords = termset.New(
	"php",
	"android",
	"java",
	"ibm",
	"github",
	"microsoft",
)

var shortWordMatch = regexp.MustCompile(`^\pL\pL?$`)

func removeHighFrequencyTerms(termToVendorProduct map[string]termset.Set, byVendorProduct map[string]*product, topNumWords int) (map[string]termset.Set, map[string]*product, termset.Set) {
	termCounts := termset.Set{}
	for _, p := range byVendorProduct {
		termCounts.AddAll(p.terms)
	}

	// get terms sorted by frequency
	terms := maps.Keys(termToVendorProduct)
	slices.SortFunc(terms, func(a, b string) int {
		numA := termCounts[a]
		numB := termCounts[b]
		if numA == numB {
			return strings.Compare(a, b)
		}
		if numA > numB {
			return -1
		}
		return 1
	})

	// set up keep words, from known list and parts of vendorProducts
	//keep := termset.New(keepWords.List()...)
	//for vp := range byVendorProduct {
	//
	//	for _, part := range vendorProductSplit.Split(vp, -1) {
	//		// 1 or 2-letter words are not especially useful
	//		if part == "" || skipWords.Has(part) || shortWordMatch.MatchString(part) {
	//			continue
	//		}
	//		keep.Add(part)
	//	}
	//}

	removeWords := termset.Set{}
	for _, term := range terms {
		if keepWords.Has(term) || isNumber(term) {
			continue
		}

		vendorProducts := termToVendorProduct[term]
		for vendorProduct := range vendorProducts {
			// if the vendorProduct text has the term, keep it regardless of the frequency seen
			keep := getTextTerms(vendorProduct)
			if keep.Has(term) {
				continue
			}

			p := byVendorProduct[vendorProduct]
			p.terms.Remove(term)
			if len(p.terms) == 0 {
				delete(byVendorProduct, vendorProduct)
			}
			vendorProducts.Remove(vendorProduct)
		}

		// if the term was not something in a vendorProduct string, delete the index entry
		if len(vendorProducts) == 0 {
			delete(termToVendorProduct, term)
		}

		removeWords.Add(term)
		topNumWords--
		if topNumWords <= 0 {
			break
		}
	}

	return termToVendorProduct, byVendorProduct, removeWords
}

func countTermInProducts(term string, byVendorProduct map[string]*product, vendorProducts termset.Set) float64 {
	total := 0.
	for vendorProduct := range vendorProducts {
		p := byVendorProduct[vendorProduct]
		if p != nil {
			total += p.terms[term]
		}
	}
	return total
}

func isNumber(term string) bool {
	_, err := strconv.ParseFloat(term, 64)
	return err == nil
}

func isHashLike(term string) bool {
	if len(term) < 6 {
		return false
	}

	numberFollowsLetter := 0
	letterFollowsNumber := 0
	last := rune(term[0])
	for _, chr := range term[1:] {
		if unicode.IsDigit(last) && unicode.IsLetter(chr) {
			letterFollowsNumber++
		}
		if unicode.IsLetter(last) && unicode.IsDigit(chr) {
			numberFollowsLetter++
		}
		last = chr
	}

	return numberFollowsLetter > 1 && letterFollowsNumber > 1
}

func readCveFile(cveFile string) (records []rec) {
	var cveRec cveRecord
	logif(json.Unmarshal(logget(os.ReadFile(cveFile)), &cveRec))

	if cveRec.CveMetadata.State == "REJECTED" {
		// skip rejected CVEs, as they may be wrong or just have no data
		return nil
	}

	if cveRec.CveMetadata.ID == "" {
		log("no cveId in:", cveFile)
		return nil
	}

	var text []string
	for _, reference := range cveRec.Containers.Cna.References {
		url := reference.Url
		if url != "" {
			text = append(text, url)
		}
	}

	for _, description := range cveRec.Containers.Cna.Descriptions {
		if description.Lang == "en" {
			text = append(text, description.Value)
		}
	}

	if len(text) == 0 {
		log("no usable text in: ", cveFile)
		return nil
	}

	cveId := normalizeCve(cveRec.CveMetadata.ID)

	for _, a := range cveRec.Containers.Cna.Affected {
		item := rec{
			cve:               cveId,
			text:              append([]string{a.Vendor, a.Product, a.PackageName}, text...),
			cpeVendorProducts: termset.Set{},
		}

		// if there are CPEs explicitly defined, use those
		for _, c := range a.Cpes {
			cpe, _ := wfn.Parse(fmt.Sprintf("%v", c))
			if cpe == nil {
				continue
			}
			cpeVendorProduct := toVendorProduct(cpe)
			item.cpeVendorProducts.Add(cpeVendorProduct)
		}

		records = append(records, item)
	}

	return records
}

func toVendorProduct(w *wfn.Attributes) string {
	//vendorProduct := fmt.Sprintf("%s:%s:%s:%s", w.Part, w.Vendor, w.Product, w.TargetSW)
	vendorProduct := fmt.Sprintf("%s:%s:%s", w.Vendor, w.Product, w.TargetSW)
	vendorProduct = strings.ReplaceAll(vendorProduct, "\\", "")
	return vendorProduct
}

func getTerms(r rec) termset.Set {
	out := termset.Set{}
	for _, txt := range r.text {
		out.AddAll(getTextTerms(txt))
	}
	return out
}

var urlPat = regexp.MustCompile(`https?://[^\s]+`)
var urlSplitter = regexp.MustCompile(`[./]`)

var keepHosts = termset.New(
	"github.com",
)

type product struct {
	cpeVendorProduct string
	cves             []string
	terms            termset.Set
}

func writeCSVFile(file string, records [][]string) {
	f := panget(os.Create(file))
	defer func() {
		logif(f.Close())
	}()
	writeCSV(f, records)
}

func writeCSV(writer io.Writer, records [][]string) {
	for _, r := range records {
		writeRow(writer, r...)
	}
}

func writeRow(writer io.Writer, values ...string) {
	for i, v := range values {
		if i > 0 {
			_ = logget(fmt.Fprint(writer, `,`))
		}
		_ = logget(fmt.Fprintf(writer, `"%s"`, v))
	}
	_ = logget(fmt.Fprintln(writer))
}

var stopwords = fetchStopwords()

func fetchStopwords() map[string]struct{} {
	//url := "https://raw.githubusercontent.com/stopwords-iso/stopwords-en/master/stopwords-en.txt"
	url := "https://gist.githubusercontent.com/rg089/35e00abf8941d72d419224cfd5b5925d/raw/12d899b70156fd0041fa9778d657330b024b959c/stopwords.txt"

	rsp := panget(http.Get(url))
	defer func() {
		logif(rsp.Body.Close())
	}()

	list := string(panget(io.ReadAll(rsp.Body)))

	words := map[string]struct{}{}
	for _, word := range strings.Split(list, "\n") {
		word = strings.TrimSpace(word)
		word = strings.ToLower(word)
		words[word] = struct{}{}
	}

	return words
}

func removeStopwords(s string) string {
	out := ""
	for _, word := range strings.Split(s, " ") {
		word = strings.TrimSpace(word)
		word = strings.ToLower(word)
		if _, ok := stopwords[word]; ok {
			continue
		}
		// more stopwords
		switch word {
		case "", "n/a", "vulnerability", "http", "https", "version":
			continue
		}
		if len(out) > 0 {
			out += " "
		}
		out += word
	}

	return out
}

//func train(csvData io.ReadSeeker) {
//	rawData, err := base.ParseCSVToInstancesFromReader(csvData, true)
//	if err != nil {
//		panic(err)
//	}
//}

//var alpha = regexp.MustCompile("[a-z ]+")

func isKnownVersionType(versionType string) bool {
	versionType = strings.ToLower(versionType)
	switch versionType {
	case "general", "release", "patch", "python", "rpm", "affected", "general availability", "semver", "maven", "original_commit_for_fix":
		return true
	default:
		return false
	}
	//return alpha.MatchString(versionType)
}

type rec struct {
	cve  string
	text []string
	//versions          []string
	cpeVendorProducts termset.Set
}
